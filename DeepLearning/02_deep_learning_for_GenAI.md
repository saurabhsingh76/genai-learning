# Deep Learning knowledge required for Generative AI Learning

## 1. Core Deep Learning Concepts

You need solid understanding of:

- **Artificial Neural Networks (ANN):** How neurons work, forward/backward propagation  
- **Training Fundamentals:** Loss functions, optimizers (Adam, SGD), gradient descent  
- **Activation Functions:** ReLU, Sigmoid, Tanh and their purposes  
- **Backpropagation:** How networks learn from errors  

## 2. Essential Neural Network Architectures

- **Feedforward Networks:** Basic multi-layer perceptrons  
- **Recurrent Neural Networks (RNN/LSTM):** For sequential data understanding  
- **Attention Mechanisms:** Foundation for transformers  
- **Basic understanding of CNNs:** Helpful for multimodal applications  

## 3. Transformers Architecture

This is critical for modern Generative AI:

- Self-attention mechanisms  
- Encoder-decoder architecture  
- How transformers process sequences  
- Understanding of positional encoding  

### Skip These Advanced Topics Initially:
- GANs (Generative Adversarial Networks): While useful, not essential for LLM-based GenAI  
- Variational Autoencoders (VAEs): More relevant for image generation  
- Complex Computer Vision: Unless doing multimodal AI  
- Advanced Optimization Techniques: Can learn as needed  

---

## Phase 1: Deep Learning Foundations

- Focus on PyTorch fundamentals (you already have this plan!)  
- Build simple neural networks for classification/regression  
- Understand tensor operations and automatic differentiation  

## Phase 2: Transformer Deep Dive

- Study the "Attention is All You Need" paper  
- Implement basic transformer components  
- Understand how text tokenization works  
- Learn about embeddings and positional encoding  

## Phase 3: LLM Fundamentals & Applications

- **Pre-trained Model Usage:** Work with existing models (GPT, BERT)  
- **Fine-tuning Techniques:** PEFT, LoRA, instruction tuning  
- **Prompt Engineering:** Designing effective prompts  
- **RAG (Retrieval Augmented Generation):** Combining LLMs with external knowledge  

---

## Practical Focus Areas

Instead of getting deep into theoretical deep learning, focus on:

- Using pre-trained models rather than training from scratch  
- Fine-tuning existing LLMs for specific tasks  
- Building applications around LLMs using frameworks like LangChain  
- RAG implementations using vector databases  
